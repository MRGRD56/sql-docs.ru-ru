---
title: Отладка и диагностика приложений Spark
titleSuffix: SQL Server Big Data Clusters
description: Используйте сервер журнала Spark для отладки и диагностики приложений Spark, работающих в кластерах больших данных SQL Server 2019.
author: jejiang
ms.author: jejiang
ms.reviewer: mikeray
ms.metadata: seo-lt-2019
ms.date: 06/22/2020
ms.topic: conceptual
ms.prod: sql
ms.technology: big-data-cluster
ms.openlocfilehash: 6bdded00e9f4cc9fb5048bf242c0333cb88f186f
ms.sourcegitcommit: 7345e4f05d6c06e1bcd73747a4a47873b3f3251f
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/24/2020
ms.locfileid: "88778523"
---
# <a name="debug-and-diagnose-spark-applications-on-big-data-clusters-2019-in-spark-history-server"></a>Отладка и диагностика приложений Spark в [!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ss-nover.md)] на сервере журнала Spark

[!INCLUDE[SQL Server 2019](../includes/applies-to-version/sqlserver2019.md)]

В этой статье содержатся указания по использованию расширенного сервера журнала Spark для отладки и диагностики приложений Spark в кластере больших данных SQL Server. Эти возможности отладки и диагностики встроены в сервер журнала Spark и обеспечиваются технологиями корпорации Майкрософт. Расширение содержит вкладки данных, графа и диагностики. На вкладке данных пользователи могут проверять входные и выходные данные задания Spark. На вкладке графа пользователи могут проверять поток данных и воспроизводить граф задания. На вкладке диагностики пользователь может просматривать результаты анализа неравномерного распределения данных, неравномерного распределения времени и использования исполнителя.

## <a name="get-access-to-spark-history-server"></a>Получение доступа к серверу журнала Spark

Интерфейс сервера журнала Spark в рамках проекта с открытым кодом дополняется такой информацией, как данные по заданиям и интерактивная визуализация графа заданий и потоков данных для кластера больших данных. 

### <a name="open-the-spark-history-server-web-ui-by-url"></a>Открытие пользовательского веб-интерфейса сервера журнала Spark по URL-адресу
Чтобы открыть сервер журнала Spark, перейдите по приведенному ниже URL-адресу, заменив `<Ipaddress>` и `<Port>` на значения для кластера больших данных. В кластерах, развернутых до выпуска накопительного пакета обновления 5 (CU5) для SQL Server 2019, с конфигурацией кластера больших данных с обычной проверкой подлинности (имя пользователя и пароль) для входа в конечные точки шлюза (Knox) необходимо предоставить учетные данные **привилегированного** пользователя. См. раздел [Развертывание кластера больших данных SQL Server](quickstart-big-data-cluster-deploy.md). [!INCLUDE [big-data-cluster-root-user](../includes/big-data-cluster-root-user.md)]

```
https://<Ipaddress>:<Port>/gateway/default/sparkhistory
```

Пользовательский веб-интерфейс сервера журнала Spark выглядит следующим образом:

![Сервер журнала Spark](./media/apache-azure-spark-history-server/spark-history-server.png)


## <a name="data-tab-in-spark-history-server"></a>Вкладка данных на сервере журнала Spark
Выберите идентификатор задания, а затем в меню инструментов выберите пункт **Данные**, чтобы открыть представление данных.

+ Выберите вкладку **Входы**, **Выходы** или **Операции с таблицей**, чтобы просмотреть соответствующие сведения.

    ![Вкладки данных на сервере журнала Spark](./media/apache-azure-spark-history-server/sparkui-data-tabs.png)

+ Чтобы скопировать все строки, нажмите кнопку **Копировать**.

    ![Копирование всех строк](./media/apache-azure-spark-history-server/sparkui-data-copy.png)

+ Чтобы сохранить все данные в CSV-файле, нажмите кнопку **CSV**.

    ![Сохранение данных в CSV-файлах](./media/apache-azure-spark-history-server/sparkui-data-save.png)

+ Чтобы выполнить поиск, введите ключевые слова в поле **поиска**. Результаты отображаются немедленно.

    ![Поиск по ключевым словам](./media/apache-azure-spark-history-server/sparkui-data-search.png)

+ Щелкните заголовок столбца для сортировки таблицы, знак "плюс", чтобы развернуть строку и просмотреть дополнительные сведения, или знак "минус", чтобы свернуть строку.

    ![Возможности таблицы данных](./media/apache-azure-spark-history-server/sparkui-data-table.png)

+ Чтобы скачать один файл, нажмите кнопку **Частичное скачивание** справа. Выбранный файл скачается в локальное расположение. Если файл больше не существует, откроется новая вкладка с сообщениями об ошибках.

    ![Скачивание строки данных](./media/apache-azure-spark-history-server/sparkui-data-download-row.png)

+ Чтобы скопировать полный или относительный путь, выберите пункт **Копировать полный путь** или **Копировать относительный путь** в меню скачивания. Для файлов Azure Data Lake Storage выбор пункта **Открыть в Обозревателе службы хранилища Azure** приводит к запуску Обозревателя службы хранилища Azure. После входа открывается указанная папка.

    ![Копирование полного или относительного пути](./media/apache-azure-spark-history-server/sparkui-data-copy-path.png)

+ Если все строки не помещаются на одной странице, щелкайте номера под таблицей для перехода по страницам. 

    ![Страница данных](./media/apache-azure-spark-history-server/sparkui-data-page.png)

+ Наведите указатель на вопросительный знак рядом с заголовком "Данные", чтобы увидеть подсказку, или щелкните вопросительный знак, чтобы получить дополнительные сведения.

    ![Дополнительные сведения](./media/apache-azure-spark-history-server/sparkui-data-more-info.png)

+ Чтобы отправить отзыв о проблемах, щелкните **Отправить нам отзыв**.

    ![обратная связь по вопросам графа](./media/apache-azure-spark-history-server/sparkui-graph-feedback.png)

## <a name="graph-tab-in-spark-history-server"></a>Вкладка графа на сервере журнала Spark

Выберите идентификатор задания, а затем в меню инструментов выберите пункт **Граф**, чтобы открыть представление графа задания.

+ Созданный граф задания позволяет получить общее представление о задании. 

+ По умолчанию отображаются все задания. Представление можно отфильтровать по **идентификатору задания**.

    ![идентификатор задания графа](./media/apache-azure-spark-history-server/sparkui-graph-jobid.png)

+ Значение по умолчанию — **Ход выполнения**. Пользователь может проверить поток данных, выбрав в раскрывающемся списке **Отображение** пункт **Чтение** или **Запись**.

    ![отображение графа](./media/apache-azure-spark-history-server/sparkui-graph-display.png)

    Узел графа отображается в цветах тепловой карты.

    ![тепловая карта графа](./media/apache-azure-spark-history-server/sparkui-graph-heatmap.png)

+ Чтобы воспроизвести задание, нажмите кнопку **Воспроизведение**. Воспроизведение можно остановить в любой момент, нажав кнопку "Стоп". Во время воспроизведения задача отображается в цвете, соответствующем состоянию.

    + Зеленый соответствует успешному выполнению: задание выполнено успешно.
    + Оранжевый соответствует повторной попытке: экземпляры задач, которые завершились со сбоем, но не влияют на конечный результат задания. Эти задачи имеют дублирующиеся или повторные экземпляры, которые могут быть успешно выполнены позже.
    + Синий соответствует выполнению: задача выполняется.
    + Белый соответствует ожиданию или пропуску: задача ожидает выполнения, либо этап пропущен.
    + Красный соответствует сбою: задачу выполнить не удалось.

    ![пример цвета графа, выполнение](./media/apache-azure-spark-history-server/sparkui-graph-color-running.png)
 
    Пропущенный этап отображается белым цветом.
    ![пример цвета графа, пропуск](./media/apache-azure-spark-history-server/sparkui-graph-color-skip.png)

    ![пример цвета графа, сбой](./media/apache-azure-spark-history-server/sparkui-graph-color-failed.png)
 
    > [!NOTE]
    > Допускается воспроизведение каждого задания. Воспроизведение незавершенных заданий не поддерживается.


+ Используйте колесико мыши для увеличения или уменьшения графа задания или щелкните **Вписать**, чтобы масштабировать его по размеру экрана.
 
    ![масштабирование графа по размеру экрана](./media/apache-azure-spark-history-server/sparkui-graph-zoom2fit.png)

+ Наведите указатель мыши на узел графа, чтобы увидеть подсказку при наличии невыполненных задач, и щелкните этап, чтобы открыть страницу этапа.

    ![подсказка к графа](./media/apache-azure-spark-history-server/sparkui-graph-tooltip.png)

+ На вкладке графа задания этапы будут иметь подсказки и небольшие значки при наличии задач, которые соответствуют указанным ниже условиям.
    + Неравномерное распределение данных: размер считанных данных > средний размер считанных данных для всех задач на этом этапе * 2 и размер считанных данных > 10 МБ
    + Неравномерное распределение времени: время выполнения > среднее время выполнения всех задач на этом этапе * 2 и время выполнения > 2 мин.

    ![значок неравномерного распределения графа](./media/apache-azure-spark-history-server/sparkui-graph-skew-icon.png)

+ В узле графа задания отображаются следующие сведения о каждом этапе:
    + ID.
    + имя или описание;
    + общее количество задач;
    + чтение данных: сумма размеров входных данных и смешанного чтения;
    + запись данных: сумма размеров выходных данных и смешанной записи;
    + время выполнения: время от начала первой попытки до завершения последней попытки;
    + число строк: сумма входных записей, выходных записей, записей смешанного чтения и записей смешанной записи;
    + ход выполнения.

    > [!NOTE]
    > По умолчанию в узле графа задания отображаются сведения о последней попытке на каждом этапе (за исключением времени выполнения этапа), но во время воспроизведения отображаются сведения о каждой попытке.

    > [!NOTE]
    > Для размера считанных и записанных данных используются соотношения 1 МБ = 1000 КБ = 1000 * 1000 байтов.

+ Чтобы отправить отзыв о проблемах, щелкните **Отправить нам отзыв**.

    ![обратная связь по вопросам графа](./media/apache-azure-spark-history-server/sparkui-graph-feedback.png)


## <a name="diagnosis-tab-in-spark-history-server"></a>Вкладка диагностики на сервере журнала Spark
Выберите идентификатор задания, а затем в меню инструментов выберите пункт **Диагностика**, чтобы открыть представление диагностики задания. На вкладке диагностики доступны вкладки **Неравномерное распределение данных**, **Неравномерное распределение времени** и **Анализ использования исполнителя**.
    
+ Выберите вкладку **Неравномерное распределение данных**, **Неравномерное распределение времени** или **Анализ использования исполнителя**, чтобы просмотреть соответствующие сведения.

    ![Вкладки диагностики](./media/apache-azure-spark-history-server/sparkui-diagnosis-tabs.png)

### <a name="data-skew"></a>Неравномерное распределение данных
Выберите вкладку **Неравномерное распределение данных**. Отобразятся соответствующие задачи с неравномерным распределением на основе указанных параметров. 

+ **Укажите параметры** — в первом разделе отображаются параметры, которые служат для обнаружения неравномерного распределения данных. Встроенное правило формулируется так: размер считанных данных задачи больше среднего размера считанных данных задачи, умноженного на три, и больше 10 МБ. Если вы хотите определить собственное правило для задач с неравномерным распределением, то можете выбрать собственные параметры. Разделы **Этап с неравномерным распределением** и **Диаграмма неравномерного распределения** обновятся соответствующим образом. 

+ **Этап с неравномерным распределением** — во втором разделе отображаются этапы, имеющие задачи с неравномерным распределением, которые отвечают указанным выше условиям. Если на этапе более одной задачи с неравномерным распределением, в таблице этапа с неравномерным распределением отображается только одна задача с наибольшим неравномерным распределением (например, наибольшим размером неравномерно распределенных данных). 

    ![Раздел 2 неравномерного распределения данных](./media/apache-azure-spark-history-server/sparkui-diagnosis-dataskew-section2.png)

+ **Диаграмма неравномерного распределения** — когда в таблице этапа с неравномерным распределением выбрана строка, на диаграмме неравномерного распределения отображаются дополнительные сведения о распределении задач на основе размера считанных данных и времени выполнения. Задачи с неравномерным распределением отмечены красным цветом, а нормальные задачи — синим. Для повышения производительности на диаграмме отображаются не более 100 образцов задач. Подробные сведения о задаче отображаются на правой нижней панели.

    ![Раздел 3 неравномерного распределения данных](./media/apache-azure-spark-history-server/sparkui-diagnosis-dataskew-section3.png)

### <a name="time-skew"></a>Неравномерное распределение времени
На вкладке **Неравномерное распределение времени** отображаются задачи с неравномерным распределением времени выполнения. 

+ **Укажите параметры** — в первом разделе отображаются параметры, которые служат для обнаружения неравномерного распределения времени. По умолчанию для обнаружения неравномерного распределения времени используется следующий критерий: время выполнения задачи больше среднего времени выполнения, умноженного на три, и превышает 30 секунд. Параметры можно изменить в соответствии с вашими потребностями. В разделах **Этап с неравномерным распределением** и **Диаграмма неравномерного распределения** отображаются соответствующие сведения об этапах и задачах, так же как на вкладке **Неравномерное распределение данных**, описанной выше.

+ Щелкните **Неравномерное распределение времени**. В разделе **Этап с неравномерным распределением** отобразятся отфильтрованные результаты в соответствии с параметрами, заданными в разделе **Укажите параметры**. Щелкните один элемент в разделе **Этап с неравномерным распределением**. Соответствующая диаграмма будет построена в разделе 3, а сведения о задаче отобразятся на правой нижней панели.

    ![Раздел 2 неравномерного распределения времени](./media/apache-azure-spark-history-server/sparkui-diagnosis-timeskew-section2.png)

### <a name="executor-usage-analysis"></a>Анализ использования исполнителя
На графе использования исполнителя визуализируются фактическое выделение и состояние выполнения задания Spark.  

+ Щелкните **Анализ использования исполнителя**. Будут построены четыре кривые, связанные с использованием исполнителя. К ним относятся **Выделенные исполнители**, **Выполняющиеся исполнители**, **Неактивные исполнители** и **Максимальное число экземпляров исполнителя**. Каждое событие "Исполнитель добавлен" или "Исполнитель удален" приводит к увеличению или уменьшению количества выделенных исполнителей. Дополнительные возможности сравнения доступны на временной шкале событий на вкладке "Задания".

    ![Вкладка исполнителей](./media/apache-azure-spark-history-server/sparkui-diagnosis-executors.png)

+ Щелкните значок цвета, чтобы выбрать соответствующее содержимое на всех графиках или отменить его выбор.

    ![Выбор диаграммы](./media/apache-azure-spark-history-server/sparkui-diagnosis-select-chart.png)
    
## <a name="spark--yarn-logs"></a>Журналы Spark и Yarn
Помимо сервера журнала Spark, журналы для Spark и Yarn соответственно можно найти в следующих местах.
* Журналы событий Spark: hdfs:///system/spark-events
* Журналы Yarn: hdfs:///tmp/logs/root/logs-tfile

Примечание. Оба этих журнала имеют период хранения по умолчанию 7 дней. Если вы хотите изменить период хранения, см. страницу [Настройка Apache Spark и Apache Hadoop](configure-spark-hdfs.md). Расположение изменить **нельзя**.

## <a name="known-issues"></a>Известные проблемы
Сервер журнала Spark имеет указанные ниже известные проблемы.

+ В настоящее время он работает только с кластером Spark 2.3.

+ Входные и выходные данные RDD не отображаются на вкладке данных.

## <a name="next-steps"></a>Дальнейшие действия

* [Начало работы с кластерами больших данных SQL Server](./deploy-get-started.md)
* Настройка параметров Spark
* [Настройка параметров Spark](/azure/hdinsight/spark/apache-spark-settings/)