---
title: Что такое развертывание приложения?
titleSuffix: SQL Server Big Data Clusters
description: Узнайте, как развертывание приложений предоставляет интерфейсы для создания и запуска приложений, а также управления ими в кластере больших данных SQL Server 2019.
author: cloudmelon
ms.author: melqin
ms.reviewer: mikeray
ms.metadata: seo-lt-2019
ms.date: 04/12/2021
ms.topic: conceptual
ms.prod: sql
dev_langs:
- yaml
- console
ms.technology: big-data-cluster
ms.openlocfilehash: 6738f43ca2b995f73ecc554406b90eabeb3424e2
ms.sourcegitcommit: 52dd1719d7b63581b1d34b755bf9d077c0fc6c44
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/13/2021
ms.locfileid: "107372992"
---
# <a name="what-is-application-deployment-on-a-sql-server-big-data-cluster"></a>Что такое развертывание приложения в кластере больших данных SQL Server?

[!INCLUDE[SQL Server 2019](../includes/applies-to-version/sqlserver2019.md)]

Развертывание приложения предоставляет интерфейсы для создания, контроля и запуска приложений в кластере больших данных SQL Server. Приложения, развертываемые в кластере больших данных, могут использовать его вычислительные ресурсы и обращаться к доступным в нем данным. Это повышает масштабируемость и производительность приложений, а также позволяет управлять ими в месте размещения данных. [!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ss-nover.md)] поддерживают среды выполнения приложений R, Python, dtexec и MLeap.

В следующих разделах описываются архитектура и функциональные возможности развертывания приложения.

## <a name="application-deployment-architecture"></a>Архитектура развертывания приложения

Развертывание приложения состоит из контроллера и обработчиков среды выполнения приложений. При создании приложения предоставляется файл спецификации (`spec.yaml`). Этот файл `spec.yaml` содержит все сведения, которые нужны контроллеру для успешного развертывания приложения. Ниже приведен пример содержимого файла `spec.yaml`.

```yaml
#spec.yaml
name: add-app #name of your python script
version: v1  #version of the app
runtime: Python #the language this app uses (R or Python)
src: ./add.py #full path to the location of the app
entrypoint: add #the function that will be called upon execution
replicas: 1  #number of replicas needed
poolsize: 1  #the pool size that you need your app to scale
inputs:  #input parameters that the app expects and the type
  x: int
  y: int
output: #output parameter the app expects and the type
  result: int
```

Контроллер проверяет элемент `runtime` в файле `spec.yaml` и вызывает соответствующий обработчик среды выполнения. Обработчик среды выполнения создает приложение. Во-первых, создается объект ReplicaSet Kubernetes, содержащий один или несколько объектов pod, каждый из которых содержит развертываемое приложение. Количество объектов pod определяется параметром `replicas`, указанным в файле `spec.yaml` для приложения. Каждый объект pod может иметь один или несколько пулов. Количество пулов определяется параметром `poolsize`, указанным в файле `spec.yaml`.

Эти параметры определяют, какой объем запросов может обрабатываться в развертывании параллельно. Максимальное количество запросов в определенный момент времени равно значению `replicas`, умноженному на `poolsize`. Если имеется 5 реплик с двумя пулами в каждой, параллельно могут обрабатываться 10 запросов. Графическое представление параметров `replicas` и `poolsize` см. на рисунке ниже.

![Poolsize и replicas](media/big-data-cluster-create-apps/poolsize-vs-replicas.png)

После создания объекта ReplicaSet и запуска пулов создается задание cron, если в файле `spec.yaml` был задан параметр `schedule`. Наконец, создается служба Kubernetes, которую можно использовать для управления приложением и его запуска (см. ниже).

При выполнении приложения служба Kubernetes передает запросы в реплику и возвращает результаты.

## <a name="security-considerations-for-applications-deployments-on-openshift"></a><a id="app-deploy-security"></a> Вопросы безопасности при развертывании приложений в OpenShift

SQL Server 2019 с накопительным пакетом обновления 5 (CU5) обеспечивает для кластеров больших данных поддержку развертывания на базе Red Hat OpenShift и обновленную модель безопасности, за счет чего привилегированные контейнеры больше не требуются. Для всех новых развертываний, использующих [SQL Server 2019 с накопительным пакетом обновления 5 (CU5)](release-notes-big-data-cluster.md#cu5), контейнеры не только являются непривилегированными, но и по умолчанию работают от имени непривилегированного пользователя.

На момент выпуска CU5 установка приложений, развертываемых с помощью интерфейсов [развертывания приложений](app-create.md), по-прежнему производилась от имени *привилегированного* пользователя. Это обусловлено тем, что в ходе установки необходимо также установить дополнительные пакеты, используемые приложением. Другой пользовательский код, развертываемый в составе приложения, выполняется от имени пользователя с низким уровнем привилегий. 

Кроме того, имеется дополнительная возможность `CAP_AUDIT_WRITE`, которая необходима для планирования работы приложений SQL Server Integration Services (SSIS) с помощью заданий cron. Если в YAML-файле спецификации приложения указано расписание, то приложение будет запускаться с помощью задания cron, для чего необходима эта дополнительная возможность. Помимо этого, приложение также можно активировать по запросу с помощью команды `azdata app run` через вызов веб-службы, для которого возможность `CAP_AUDIT_WRITE` не требуется. Обратите внимание, что возможность `CAP_AUDIT_WRITE` больше не требуется для `cronjob`, начиная с выпуска SQL Server 2019 с накопительным пакетом обновления 8 (CU8). 



> [!NOTE]
> Настраиваемое ограничение контекста безопасности (SCC) из [статьи по развертыванию в OpenShift](deploy-openshift.md) не включает эту возможность, так как она не требуется для развертывания кластера больших данных по умолчанию. Чтобы включить эту возможность, сначала измените пользовательский YAML-файл SCC и включите в него CAP_AUDIT_WRITE.

```yaml
...
allowedCapabilities:
- SETUID
- SETGID
- CHOWN
- SYS_PTRACE
- AUDIT_WRITE
...
```

## <a name="how-to-work-with-app-deploy-inside-big-data-cluster"></a>Развертывание приложения в кластере больших данных

Развертывание приложения имеет два основных интерфейса: 

- [интерфейс командной строки [!INCLUDE [azure-data-cli-azdata](../includes/azure-data-cli-azdata.md)];](app-create.md)
- [расширение для Visual Studio Code и Azure Data Studio.](app-deployment-extension.md)

Приложение может также выполняться с помощью веб-службы RESTful. Дополнительные сведения см. в статье [Использование приложений в кластерах больших данных](app-consume.md).

## <a name="app-deploy-scenarios"></a>Сценарии развертывания приложения

Развертывание приложения предоставляет интерфейсы для создания, контроля и запуска приложений в кластере больших данных SQL Server.

:::image type="content" source="media/concept-application-deployment/big-data-cluster-app-pool-process-overview.png" alt-text="Определение источников (R, Python, SSIS (dtexec)), развертывание с помощью командной строки, Azure Data Studio или Visual Studio Code и получение из источников данных по интерактивному расписанию API RESTful.":::

Целевые сценарии развертывания приложения:

- Развертывание веб-служб Python или R в кластере больших данных для различных вариантов использования, таких как вывод машинного обучения, обслуживание API и т. д.
- Создание конечной точки вывода машинного обучения с использованием подсистемы MLeap.
- Планирование работы и запуск пакетов из файлов DTSX с помощью служебной программы dtexec для целей преобразования и перемещения данных.

### <a name="use-app-deploy-python-runtime"></a>Использование среды выполнения Python для развертывания приложения

Развертывание приложения позволяет применять среду выполнения приложений Python в кластере больших данных для различных вариантов использования, таких как вывод машинного обучения, обслуживание API и многие другие.

Python 3.5 для Ubuntu 16.04 и Python 3.8 для Ubuntu 20.04.

В файле `spec.yaml` указываются сведения, необходимые контроллеру для развертывания приложения. Ниже перечислены поля, которые можно указать.

- `name`: имя приложения.
- `version`: версия приложения, например `v1`.
- `runtime`: среда выполнения развертывания приложения. Ее необходимо указать как `Python`.
- `src`: путь к приложению Python.
- `entry point`: функция точки входа в скрипте src, выполняемом для этого приложения Python.

Помимо значений выше, необходимо указать входные и выходные данные приложения Python. Будет создан файл `spec.yaml` следующего вида:

```yaml
#spec.yaml
name: add-app
version: v1
runtime: Python
src: ./add.py
entrypoint: add
replicas: 1
poolsize: 1
inputs:
  x: int
  y: int
output:
  result: int
```

Вы можете создать базовую структуру папок и файлов, необходимую для развертывания приложения Python, запускаемого в кластере больших данных:

```console
azdata app init --template python --name hello-py --version v1
```

Дальнейшие действия см. в статье [Развертывание приложения в кластерах больших данных SQL Server](app-create.md).

#### <a name="app-deploy-python-runtime-limitations"></a>Ограничения среды выполнения Python для развертывания приложения

Среда выполнения Python для развертывания приложения не поддерживает сценарий планирования, при котором после развертывания приложения Python и его запуска в кластере больших данных настраивается конечная точка RESTful для ожидания входящих запросов.

### <a name="use-app-deploy-r-runtime"></a>Использование среды выполнения R для развертывания приложения

Развертывание приложения позволяет применять среду выполнения Python в кластере больших данных для различных вариантов использования приложения R, таких как вывод машинного обучения, обслуживание API и многие другие.

Среда выполнения R для развертывания приложения поддерживает Microsoft R Open (MRO) 3.5.2.

#### <a name="how-to-use-it"></a>Использование

В файле `spec.yaml` указываются сведения, необходимые контроллеру для развертывания приложения. Ниже перечислены поля, которые можно указать.

- `name`: имя приложения.
- `version`: версия приложения, например `v1`.
- `runtime`: среда выполнения развертывания приложения. Ее необходимо указать как `R`.
- `src`: путь к приложению R.
- `entry point`: точка входа для выполнения этого приложения R.

Помимо значений выше, необходимо указать входные и выходные данные приложения R. Будет создан файл `spec.yaml` следующего вида:

```yaml
#spec.yaml
name: roll-dice
version: v1
runtime: R
src: ./roll-dice.R
entrypoint: rollEm
replicas: 1
poolsize: 1
inputs:
  x: integer
output:
  result: data.fram
```

Вы можете создать базовую структуру папок и файлов, необходимую для развертывания нового приложения R, с помощью следующей команды:

```console
azdata app init --template r --name hello-r --version v1
```

Дальнейшие действия см. в статье [Развертывание приложения в кластерах больших данных SQL Server](app-create.md).

#### <a name="more-details-on-limitations"></a>Дополнительные сведения об ограничениях

Ограничения соответствуют [Microsoft R Application Network](https://mran.microsoft.com/open).

### <a name="using-app-deploy-dtexec-runtime"></a>Использование среды выполнения dtexec для развертывания приложения

Развертывание приложения использует служебную программу dtexec из SSIS для Linux (mssql-server-is), интегрированную в среду выполнения кластера больших данных. Служебная программа dtexe используется в развертывании приложения для загрузки пакетов из файлов DTSX. Она поддерживает запуск пакетов SSIS по расписанию в стиле cron или по требованию через запросы веб-службы.

Эта функция использует `/opt/ssis/bin/dtexec /FILE` и поддерживает формат DTSX [службы интеграции SQL Server 2019 для Linux (mssql-server-is 15.0.2)](../linux/sql-server-linux-setup-ssis.md). См. дополнительные сведения о [служебной программе dtexec](../integration-services/packages/dtexec-utility.md).

В файле `spec.yaml` указываются сведения, необходимые контроллеру для развертывания приложения. Ниже перечислены поля, которые можно указать.

- `name`: имя (`name`) приложения.
- `version`: версия приложения, например `v1`.
- `runtime`: среда выполнения развертывания приложения. Для запуска служебной программы dtexec необходимо указать ее как `SSIS`.
- `entrypoint`: точка входа. Обычно это DTSX-файл.
- `options`: дополнительные параметры для `/opt/ssis/bin/dtexec /FILE`. Например, для соединения с базой данных с помощью строки подключения используется следующий шаблон: 

   ```console
   /REP V /CONN "sqldatabasename"\;"\"Data Source=xx;User ID=xx;Password=xx\""
   ```

  Сведения о синтаксисе см. в описании [служебной программы dtexec](../integration-services/packages/dtexec-utility.md).

- `schedule`: указание частоты выполнения задания. Например, если с помощью выражения cron указать значение "*/1 * * * *", то задание будет выполняться раз в минуту.

Вы можете создать базовую структуру папок и файлов, необходимую для развертывания нового приложения SSIS, с помощью следующей команды:

```console
azdata app init --name hello-is –version v1 --template ssis                                 
```

Будет создан файл `spec.yaml` следующего вида:

```yaml
#spec.yaml
entrypoint: ./hello.dtsx
name: hello-is
options: /REP V
poolsize: 2
replicas: 2
runtime: SSIS
schedule: '*/2 * * * *'
version: v1
```

В примере также создается образец пакета `hello.dtsx`.

Все файлы приложения находятся в том же каталоге, что и файл `spec.yaml`. Файл `spec.yaml` должен находиться на корневом уровне папки с исходным кодом приложения, включающей файл DTSX.

Дальнейшие действия см. в статье [Развертывание приложения в кластерах больших данных SQL Server](app-create.md).

#### <a name="limitations-of-dtsx-utility"></a>Ограничения для служебной программы dtsx

Для этого компонента действуют все ограничения и известные проблемы SQL Server Integration Services (SSIS) для Linux. Дополнительные сведения: [Ограничения и известные проблемы для служб SSIS в Linux](../linux/sql-server-linux-ssis-known-issues.md).

### <a name="using-app-deploy-mleap-runtime"></a>Использование среды выполнения MLeap для развертывания приложений

Среда выполнения MLeap для развертывания приложений поддерживает MLeap Serving v0.13.0.

В файле `spec.yaml` указываются сведения, необходимые контроллеру для развертывания приложения. Ниже перечислены поля, которые можно указать.

- `name`: имя приложения. 
- `version`: версия приложения, например `v1`. 
- `runtime`: среда выполнения развертывания приложения. Ее необходимо указать как `Mleap`.

Помимо значений выше, необходимо указать `bundleFileName` для вашего приложения MLeap. Будет создан файл `spec.yaml` следующего вида:

```yaml
#spec.yaml
name: mleap-census
version: v1
runtime: Mleap
bundleFileName: census-bundle.zip
replicas: 1
```

Вы можете создать базовую структуру папок и файлов, необходимую для развертывания нового приложения MLeap, с помощью следующей команды:

```console
azdata app init --template mleap --name hello-mleap --version v1
```

Дальнейшие действия см. в статье [Развертывание приложения в кластерах больших данных SQL Server](app-create.md).

#### <a name="mleap-limitations"></a>Ограничения MLeap

Ограничения соответствуют концепции проекта MLeap с открытым исходным кодом от Сombust на [GitHub](https://github.com/combust/mleap).

## <a name="next-steps"></a>Дальнейшие действия

Дополнительные сведения о создании и выполнении приложений в [!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ss-nover.md)] см. в следующих статьях:

- [Развертывание приложений с помощью azdata](app-create.md)
- [Использования расширения для развертывания приложения](app-deployment-extension.md)
- [Использование приложений в кластерах больших данных](app-consume.md)

Дополнительные сведения о [!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ss-nover.md)] см. в следующем обзоре:

- [Что такое [!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ver15.md)]?](big-data-cluster-overview.md)
